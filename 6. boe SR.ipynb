{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from tqdm import tqdm\n",
    "import classla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./data/corpus.csv\"\n",
    "corpus = pd.read_csv(\"./data/corpus.csv\", dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"SR\"\n",
    "data = corpus[corpus.NaturalLanguageID == language]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"Comment\", \"y8\", \"y6\", \"y2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove ide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.y8 != \"ide\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = 0\n",
    "total_tokens_without_embedding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_vector(embeddings, comment):\n",
    "    global total_tokens, total_tokens_without_embedding\n",
    "\n",
    "    comment_vector = []\n",
    "    num_tokens = 0\n",
    "\n",
    "    for token in comment:\n",
    "        total_tokens += 1\n",
    "        try:\n",
    "            if num_tokens == 0:\n",
    "                comment_vector = embeddings[token]\n",
    "            else:\n",
    "                comment_vector = np.add(comment_vector, embeddings[token])\n",
    "            num_tokens += 1\n",
    "        except:\n",
    "            total_tokens_without_embedding += 1\n",
    "            pass\n",
    "    if num_tokens == 0:\n",
    "        return np.nan\n",
    "    return np.asarray(comment_vector) / num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(comments, embeddings):\n",
    "    global total_tokens, total_tokens_without_embedding\n",
    "\n",
    "    total_tokens = 0\n",
    "    total_tokens_without_embedding = 0\n",
    "\n",
    "    X_vectors = comments.apply(lambda comment: get_comment_vector(embeddings, comment))\n",
    "    X_vectors = X_vectors.apply(pd.Series)\n",
    "\n",
    "    nan_comments_mask = X_vectors.isnull().iloc[:, 0]\n",
    "    num_nan_comments = nan_comments_mask.sum()\n",
    "    print(f\"{num_nan_comments} comments have no embeddings\")\n",
    "\n",
    "    print (f\"Total tokens {total_tokens}, out of whicih {total_tokens_without_embedding} do not have embeddings -- {total_tokens_without_embedding/total_tokens*100:.4}%.\")\n",
    "    return X_vectors, nan_comments_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_file, score_name, score_value):\n",
    "    pd.DataFrame(\n",
    "        {\"score_name\": [score_name],\n",
    "        \"score_value\": [score_value]}\n",
    "    ).to_csv(result_file, mode=\"a\", decimal=\",\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_name(score_name, model_name, num_classes):\n",
    "    return f\"{score_name}-{model_name}-{num_classes}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, x_column_name, y_column_name, result_file, score_name, model_name, estimator, hyper_params, embeddings):\n",
    "    print(estimator)\n",
    "    \n",
    "    X = data[x_column_name]\n",
    "    y = data[y_column_name]\n",
    "\n",
    "    # Vectorize.\n",
    "    X, nan_comments_mask = vectorize(X, embeddings)\n",
    "    X = X[~nan_comments_mask]\n",
    "    y = y[~nan_comments_mask]\n",
    "\n",
    "    full_score_name = make_score_name(score_name, model_name, y.nunique())\n",
    "    print(f\"--------Evaluating {full_score_name} --------\")\n",
    "    gs_estimator = GridSearchCV(\n",
    "        estimator, hyper_params, scoring=\"f1_macro\", cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42), verbose=0, n_jobs=-1)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        gs_estimator, X, y, scoring=\"f1_macro\", cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42), verbose=0, n_jobs=-1)\n",
    "    mean_score = np.mean(scores[\"test_score\"])\n",
    "\n",
    "    pd.DataFrame(\n",
    "        {\"score_name\": [full_score_name],\n",
    "        \"score_value\": [mean_score]}\n",
    "    ).to_csv(result_file, mode=\"a\", decimal=\",\", header=False, index=False)\n",
    "\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classla.download('sr', type='nonstandard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_pipeline = classla.Pipeline(\"sr\", type=\"nonstandard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classla_tokenize(comment):\n",
    "    try:\n",
    "        doc = sr_pipeline(comment)\n",
    "        return list([word.text for word in doc.iter_words()])\n",
    "    except:\n",
    "        print(f\"SR tokenize ERROR for comment: {comment}\")\n",
    "        return comment.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "data[\"classla_tokens\"] = data[\"Comment\"].progress_apply(lambda comment: classla_tokenize(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "\n",
    "def my_whitespace_tokenizer(comment):\n",
    "    return whitespace_tokenizer.tokenize(comment)\n",
    "\n",
    "data[\"whitespace_tokens\"] = data[\"Comment\"].apply(lambda comment: my_whitespace_tokenizer(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_word_tokenizer(comment):\n",
    "    token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    return token_pattern.findall(comment)\n",
    "\n",
    "data[\"word_tokens\"] = data[\"Comment\"].apply(lambda comment: my_word_tokenizer(comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_params = {\n",
    "    \"svm\": (LinearSVC(), {\"C\": [0.001, 0.01, 0.1, 1, 10]}), \n",
    "    # \"log\": (LogisticRegression(max_iter=800), {\"C\": [0.001, 0.01, 0.1, 1, 10]}), \n",
    "    # \"mnb\": (MultinomialNB(), {\"alpha\": [0.001, 0.01, 0.1, 1, 10]})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/boe_SR.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read embeddings cc_sh_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file, vectors_name = (\"embeddings/cc.sh.300.vec\", \"cc_sh_300\")\n",
    "print(f\"Start reading {embedding_file}.\")\n",
    "embeddings_cc = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "print(f\"End reading {embedding_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"classla_tokens\", \"whitespace_tokens\",\"word_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_cc)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. snake_case/CamelCase/both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snake_case_tokenize(tokens):\n",
    "    output_tokens = []\n",
    "    for token in tokens:\n",
    "        output_tokens.extend(token.split(\"_\"))\n",
    "\n",
    "    return list(filter(None, output_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"snake_classla_tokens\"] = data[\"classla_tokens\"].apply(lambda tokens: snake_case_tokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_case_tokenize(tokens):\n",
    "    try:\n",
    "        output_tokens = []\n",
    "        for token in tokens:\n",
    "            if len(token) == 0:\n",
    "                continue\n",
    "            new_tokens = []\n",
    "            new_tokens.append(str(token[0]))\n",
    "            for c in token[1:]:\n",
    "                if new_tokens[-1][-1].islower() and c.isupper():\n",
    "                    new_tokens.append(str(c))\n",
    "                else:\n",
    "                    new_tokens[-1] += c\n",
    "\n",
    "            output_tokens.extend(new_tokens)\n",
    "\n",
    "        return list(filter(None, output_tokens))\n",
    "    except:\n",
    "        print(\"-------------- CAMEL CASE ERROR ------------\")\n",
    "        print(tokens)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"camel_classla_tokens\"] = data[\"classla_tokens\"].apply(lambda tokens: camel_case_tokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"snake_camel_classla_tokens\"] = data[\"snake_classla_tokens\"].apply(lambda tokens: camel_case_tokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"snake_classla_tokens\", \"camel_classla_tokens\",\"snake_camel_classla_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_cc)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_df = pd.read_csv(\"data/tokens/SR_classla_stemmed.csv\", header=0, dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_df.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"stemmed_classla_tokens\"] = stemmed_df[\"stemmed_classla_tokens\"].apply(lambda comment: comment.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_pretokenized_pipeline = classla.Pipeline(\n",
    "    \"sr\", type=\"nonstandard\", tokenize_pretokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_sr(tokens):\n",
    "    try:\n",
    "        doc = sr_pretokenized_pipeline(\" \".join(tokens))\n",
    "        return list([word.lemma for word in doc.iter_words()])\n",
    "    except:\n",
    "        print(f\"Lema SR error for tokens: {tokens}\")\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "data[\"lema_classla_tokens\"] = data[\"classla_tokens\"].progress_apply(lambda tokens: lemma_sr(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"stemmed_classla_tokens\", \"lema_classla_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_cc)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"classla_tokens_lower\"] = data[\"classla_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"classla_tokens_lower\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_cc)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Remove punctuation/numbers/both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "data[\"classla_nopunctuation_tokens\"] = data[\"Comment\"].progress_apply(lambda comment: classla_tokenize(re.sub(r\"[^\\w\\s]\", \" \", comment)))\n",
    "data[\"classla_nonumbers_tokens\"] = data[\"Comment\"].progress_apply(lambda comment: classla_tokenize(re.sub(r\"[0-9]+\", \" \", comment)))\n",
    "data[\"classla_nopunctuationnumbers_tokens\"] = data[\"Comment\"].progress_apply(lambda comment: classla_tokenize(re.sub(r\"[0-9]+\", \" \", re.sub(r\"[^\\w\\s]\", \" \", comment))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"classla_nopunctuation_tokens\", \"classla_nonumbers_tokens\", \"classla_nopunctuationnumbers_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_cc)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read embeddings cc_sr_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file, vectors_name = (\"embeddings/cc.sr.300.vec\", \"cc_sr_300\")\n",
    "print(f\"Start reading {embedding_file}.\")\n",
    "embeddings_sr = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "print(f\"End reading {embedding_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\n",
    "            #\"classla_tokens\", \"whitespace_tokens\", \"word_tokens\", \n",
    "                    # \"snake_classla_tokens\", \"camel_classla_tokens\",\"snake_camel_classla_tokens\", \n",
    "                    # \"stemmed_classla_tokens\", \"lema_classla_tokens\",\n",
    "                    # \"classla_tokens_lower\", \n",
    "                    # \"classla_nopunctuation_tokens\", \n",
    "                    \"classla_nonumbers_tokens\", \"classla_nopunctuationnumbers_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_sr)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read embeddings embed.hr-token.ft.sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file, vectors_name = (\"embeddings/embed.hr-token.ft.sg.vec\", \"embed_hr\")\n",
    "print(f\"Start reading {embedding_file}.\")\n",
    "embeddings_hr = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "print(f\"End reading {embedding_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"classla_tokens\", \"whitespace_tokens\", \"word_tokens\", \n",
    "                    \"snake_classla_tokens\", \"camel_classla_tokens\",\"snake_camel_classla_tokens\", \n",
    "                    \"stemmed_classla_tokens\", \"lema_classla_tokens\",\n",
    "                    \"classla_tokens_lower\", \n",
    "                    \"classla_nopunctuation_tokens\", \"classla_nonumbers_tokens\", \"classla_nopunctuationnumbers_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_hr)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"lower_lema_classla_tokens\"] = data[\"lema_classla_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"lower_lema_classla_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_hr)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file, vectors_name = (\"embeddings/cc.sr.300.vec\", \"cc_sr_300\")\n",
    "print(f\"Start reading {embedding_file}.\")\n",
    "embeddings_sr = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "print(f\"End reading {embedding_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"lower_lema_classla_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_sr)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file, vectors_name = (\"embeddings/cc.sh.300.vec\", \"cc_sh_300\")\n",
    "print(f\"Start reading {embedding_file}.\")\n",
    "embeddings_cc = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "print(f\"End reading {embedding_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\"lower_lema_classla_tokens\"]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_cc)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "data[\"lema_classla_nopunctuation_tokens\"] = data[\"Comment\"].progress_apply(lambda comment: lemma_sr(classla_tokenize(re.sub(r\"[^\\w\\s]\", \" \", comment))))\n",
    "data[\"lema_classla_nonumbers_tokens\"] = data[\"Comment\"].progress_apply(lambda comment: lemma_sr(classla_tokenize(re.sub(r\"[0-9]+\", \" \", comment))))\n",
    "data[\"lema_classla_nopunctuationnumbers_tokens\"] = data[\"Comment\"].progress_apply(lambda comment: lemma_sr(classla_tokenize(re.sub(r\"[0-9]+\", \" \", re.sub(r\"[^\\w\\s]\", \" \", comment)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"lower_lema_classla_nopunctuation_tokens\"] = data[\"lema_classla_nopunctuation_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])\n",
    "data[\"lower_lema_classla_nonumbers_tokens\"] = data[\"lema_classla_nonumbers_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])\n",
    "data[\"lower_lema_classla_nopunctuationnumbers_tokens\"] = data[\"lema_classla_nopunctuationnumbers_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (embedding_file, vectors_name) in [(\"embeddings/embed.hr-token.ft.sg.vec\", \"embed_hr\"), (\"embeddings/cc.sr.300.vec\", \"cc_sr_300\"), (\"embeddings/cc.sh.300.vec\", \"cc_sh_300\")]:\n",
    "    print(f\"Start reading {embedding_file}.\")\n",
    "    embeddings = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "    print(f\"End reading {embedding_file}.\")\n",
    "\n",
    "    for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "        for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "            # Try different tokenizers\n",
    "            scores = {}\n",
    "            for x_name in [\"lema_classla_nopunctuation_tokens\", \"lema_classla_nonumbers_tokens\", \"lema_classla_nopunctuationnumbers_tokens\", \n",
    "                            \"lower_lema_classla_nopunctuation_tokens\", \"lower_lema_classla_nonumbers_tokens\", \"lower_classla_nopunctuationnumbers_tokens\"]:\n",
    "                score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings)\n",
    "                scores[x_name] = score\n",
    "            print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"lower_classla_nopunctuation_tokens\"] = data[\"classla_nopunctuation_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])\n",
    "data[\"lower_classla_nonumbers_tokens\"] = data[\"classla_nonumbers_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])\n",
    "data[\"lower_classla_nopunctuationnumbers_tokens\"] = data[\"classla_nopunctuationnumbers_tokens\"].apply(lambda tokens: [token.lower() for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (embedding_file, vectors_name) in [(\"embeddings/embed.hr-token.ft.sg.vec\", \"embed_hr\"), (\"embeddings/cc.sr.300.vec\", \"cc_sr_300\"), (\"embeddings/cc.sh.300.vec\", \"cc_sh_300\")]:\n",
    "    print(f\"Start reading {embedding_file}.\")\n",
    "    embeddings = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "    print(f\"End reading {embedding_file}.\")\n",
    "\n",
    "    for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "        for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "            # Try different tokenizers\n",
    "            scores = {}\n",
    "            for x_name in [\"lower_classla_nopunctuation_tokens\", \"lower_classla_nonumbers_tokens\", \"lower_classla_nopunctuationnumbers_tokens\"]:\n",
    "                score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings)\n",
    "                scores[x_name] = score\n",
    "            print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(embedding_file, vectors_name) = (\"embeddings/embed.sr-token.ft.sg.vec\", \"embed_sr\")\n",
    "print(f\"Start reading {embedding_file}.\")\n",
    "embeddings_sr = KeyedVectors.load_word2vec_format(embedding_file)\n",
    "print(f\"End reading {embedding_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (estimator, hyper_params) in evaluation_params.items():\n",
    "    for y_name in [\"y8\", \"y6\", \"y2\"]:\n",
    "        # Try different tokenizers\n",
    "        scores = {}\n",
    "        for x_name in [\n",
    "                \"classla_tokens\", \"whitespace_tokens\", \"word_tokens\", \n",
    "                \"snake_classla_tokens\", \"camel_classla_tokens\",\"snake_camel_classla_tokens\", \n",
    "                \"stemmed_classla_tokens\", \"lema_classla_tokens\",\n",
    "                \"classla_tokens_lower\", \"lower_lema_classla_tokens\",\n",
    "                \"lema_classla_nopunctuation_tokens\", \"lema_classla_nonumbers_tokens\", \"lema_classla_nopunctuationnumbers_tokens\", \n",
    "                \"lower_lema_classla_nopunctuation_tokens\", \"lower_lema_classla_nonumbers_tokens\", \"lower_lema_classla_nopunctuationnumbers_tokens\",\n",
    "                \"classla_nopunctuation_tokens\", \"classla_nonumbers_tokens\", \"classla_nopunctuationnumbers_tokens\",\n",
    "                \"lower_classla_nopunctuation_tokens\", \"lower_classla_nonumbers_tokens\", \"lower_classla_nopunctuationnumbers_tokens\"\n",
    "                ]:\n",
    "            score = evaluate(data, x_name, y_name, result_file, vectors_name+\"-\"+x_name, model_name, estimator, hyper_params, embeddings_sr)\n",
    "            scores[x_name] = score\n",
    "        print(f\"{model_name}-{y_name}-best-{max(scores, key=scores.get)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
