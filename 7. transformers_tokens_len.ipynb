{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649072976261
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_tokens_len(language, model_type, model_name, max_seq_len = 512):\n",
        "    print(f\"Language {language}, model_name = {model_name}, model_type = {model_type}\")\n",
        "    parameter_dict = {}\n",
        "    parameter_dict[\"fp16\"] = False\n",
        "    # parameter_dict[\"manual_seed\"] = 64\n",
        "    parameter_dict[\"overwrite_output_dir\"] = True\n",
        "    parameter_dict[\"reprocess_input_data\"] = True\n",
        "    parameter_dict[\"no_cache\"] = True\n",
        "    parameter_dict[\"save_eval_checkpoints\"] = False\n",
        "    parameter_dict[\"save_model_every_epoch\"] = False\n",
        "    parameter_dict[\"use_cached_eval_features\"] = False\n",
        "    parameter_dict[\"output_dir\"] = f\"./Transformers/{model_name}/outputs/\"\n",
        "    parameter_dict[\"cache_dir\"] = f\"./Transformers/{model_name}/cache/\"\n",
        "    parameter_dict[\"tensorboard_dir\"] = f\"./Transformers/{model_name}/runs/\"\n",
        "    parameter_dict[\"silent\"] = True\n",
        "    # parameter_dict[\"do_lower_case\"] = lowercase\n",
        "    parameter_dict[\"num_train_epochs\"] = 1\n",
        "    parameter_dict[\"max_seq_length\"] = max_seq_len\n",
        "    # parameter_dict[\"sliding_window\"] = sliding_window\n",
        "\n",
        "    corpus = pd.read_csv(\"./data/corpus.csv\", dtype=str)\n",
        "    print(corpus.shape)\n",
        "    data = corpus[corpus.NaturalLanguageID == language]\n",
        "    X = data[\"Comment\"].astype(str)\n",
        "    y = data[\"y2\"]\n",
        "    num_classes = y.nunique()\n",
        "\n",
        "    # Convert string classes to numbers.\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    y=pd.Series(le.fit_transform(y))\n",
        "\n",
        "    # Prepare data.\n",
        "    train_df = pd.DataFrame(list(zip(X, y)), columns=['text', 'labels'])\n",
        "\n",
        "    try:\n",
        "        # Create model.\n",
        "        model = ClassificationModel(model_type, model_name, num_labels=num_classes, use_cuda=True, args=parameter_dict)  # You can set class weights by using the optional weight argument\n",
        "        # Train model.\n",
        "        _, _ = model.train_model(train_df, show_running_loss=False, verbose=False)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_tokens_len(language=\"SR\", model_type=\"electra\", model_name=\"classla/bcms-bertic\", max_seq_len=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_tokens_len(language=\"EN\", model_type=\"electra\", model_name=\"google/electra-base-discriminator\", max_seq_len=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_tokens_len(language=\"SR\", model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", max_seq_len=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_tokens_len(language=\"EN\", model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", max_seq_len=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_tokens_len(language=\"SR\", model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", max_seq_len=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_tokens_len(language=\"EN\", model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", max_seq_len=5000)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "0571e55f8ecb5572eaff1245df35f6abd89dfb1033fe8a1cd84758258f152333"
    },
    "kernel_info": {
      "name": "newenvtf"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
