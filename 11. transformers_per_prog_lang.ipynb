{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./data/corpus.csv\"\n",
    "corpus = pd.read_csv(\"./data/corpus.csv\", dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"ProgrammingLanguageID\"] = corpus[\"ProgrammingLanguageID\"].apply(lambda lang: \"JS/TS\" if lang == \"JavaScript\" or lang == \"TypeScript\" else lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalLanguageID</th>\n",
       "      <th>ProgrammingLanguageID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>ClassM</th>\n",
       "      <th>ClassA</th>\n",
       "      <th>y8</th>\n",
       "      <th>y6</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>#include \"map_in_map.h\"</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>- offsetof(struct bpf_array, value);</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>array-&gt;index_mask = index_mask;</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>bpf_map_charge_move(&amp;array-&gt;map.memory, &amp;mem);</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>array-&gt;elem_size = elem_size;</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NaturalLanguageID ProgrammingLanguageID  \\\n",
       "0                EN                     C   \n",
       "1                EN                     C   \n",
       "2                EN                     C   \n",
       "3                EN                     C   \n",
       "4                EN                     C   \n",
       "\n",
       "                                          Comment ClassM ClassA    y8    y6  \\\n",
       "0                         #include \"map_in_map.h\"   code   code  code  code   \n",
       "1            - offsetof(struct bpf_array, value);   code   <NA>  code  code   \n",
       "2                 array->index_mask = index_mask;   code   <NA>  code  code   \n",
       "3  bpf_map_charge_move(&array->map.memory, &mem);   code   <NA>  code  code   \n",
       "4                   array->elem_size = elem_size;   code   <NA>  code  code   \n",
       "\n",
       "               y2  \n",
       "0  non-functional  \n",
       "1  non-functional  \n",
       "2  non-functional  \n",
       "3  non-functional  \n",
       "4  non-functional  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "corpus[\"y2\"]=pd.Series(le.fit_transform(corpus[\"y2\"]))\n",
    "corpus[\"y6\"]=pd.Series(le.fit_transform(corpus[\"y6\"]))\n",
    "corpus[\"y8\"]=pd.Series(le.fit_transform(corpus[\"y8\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'C#', 'C++', 'Java', 'JS/TS', 'PHP', 'Python', 'SQL'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.ProgrammingLanguageID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR_data = corpus[corpus.NaturalLanguageID == \"SR\"]\n",
    "# Remove IDE to be consistent with other models.\n",
    "SR_data = SR_data[SR_data.y8 != \"ide\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_data = corpus[corpus.NaturalLanguageID == \"EN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_name(lang_name, score_name, model_name, num_classes):\n",
    "    return f\"{lang_name}-{score_name}-{model_name}-{num_classes}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro_score(y, y_pred):\n",
    "    return f1_score(y, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_file, score_name, score_value):\n",
    "    pd.DataFrame(\n",
    "        {\"score_name\": [score_name],\n",
    "        \"score_value\": [score_value]}\n",
    "    ).to_csv(result_file, mode=\"a\", decimal=\",\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lang(data_train, data_test, test_lang_name, result_file, model_type, model_name, num_epochs, y_column_names=[\"y8\",\"y6\", \"y2\"], seeds=[11, 17, 23, 47, 62]):\n",
    "    parameter_dict = {}\n",
    "    parameter_dict[\"fp16\"] = False\n",
    "    parameter_dict[\"overwrite_output_dir\"] = True\n",
    "    parameter_dict[\"reprocess_input_data\"] = True\n",
    "    parameter_dict[\"no_cache\"] = True\n",
    "    parameter_dict[\"save_eval_checkpoints\"] = False\n",
    "    parameter_dict[\"save_model_every_epoch\"] = False\n",
    "    parameter_dict[\"use_cached_eval_features\"] = False\n",
    "    parameter_dict[\"output_dir\"] = f\"./Transformers/{model_name}/outputs/\"\n",
    "    parameter_dict[\"cache_dir\"] = f\"./Transformers/{model_name}/cache/\"\n",
    "    parameter_dict[\"tensorboard_dir\"] = f\"./Transformers/{model_name}/runs/\"\n",
    "    parameter_dict[\"silent\"] = True\n",
    "    parameter_dict[\"num_train_epochs\"] = num_epochs\n",
    "    parameter_dict[\"max_seq_length\"] = 512\n",
    "\n",
    "    X_train = data_train[\"Comment\"].astype(str)\n",
    "    X_test = data_test[\"Comment\"].astype(str)\n",
    "\n",
    "    for y_column_name in y_column_names:\n",
    "        seed_scores = []\n",
    "        \n",
    "        for manual_seed in seeds:\n",
    "            parameter_dict[\"manual_seed\"] = manual_seed\n",
    "\n",
    "            y_train = data_train[y_column_name]\n",
    "            y_test = data_test[y_column_name]\n",
    "\n",
    "            num_classes = y_test.nunique()\n",
    "\n",
    "            score_name = make_score_name(test_lang_name, f\"epochs{num_epochs}\", model_name, num_classes)\n",
    "            t = time.strftime(\"%H:%M:%S\",time.localtime())\n",
    "            print(f\"-------------------{t} RUNNING {score_name}-seed{manual_seed} with {num_classes} classes.-------------------\")\n",
    "\n",
    "            print(\"X_train shape\", X_train.shape, \"y_train shape\", y_train.shape)\n",
    "\n",
    "            train_df = pd.DataFrame(list(zip(X_train, y_train)), columns=['text', 'labels'])\n",
    "            eval_df = pd.DataFrame(list(zip(X_test, y_test)), columns=['text', 'labels'])\n",
    "\n",
    "            # Create model.\n",
    "            model = ClassificationModel(model_type, model_name, num_labels=y_train.nunique(), use_cuda=True, args=parameter_dict)  # You can set class weights by using the optional weight argument\n",
    "            # Train model.\n",
    "            global_step, training_details = model.train_model(train_df, show_running_loss=False, verbose=False)\n",
    "            print(global_step, training_details)\n",
    "            # Evaluate model.\n",
    "            t = time.strftime(\"%H:%M:%S\",time.localtime())\n",
    "            print(f\"-------------------{t} EVALUATE model-------------------\")\n",
    "            result, y_pred, wrong_predictions = model.eval_model(eval_df, f1=f1_macro_score, verbose=False)\n",
    "\n",
    "            # Get results.\n",
    "            print(\"RESULT \", result)\n",
    "            macro_f1 = result[\"f1\"]\n",
    "            seed_scores.append(macro_f1)\n",
    "\n",
    "            t = time.strftime(\"%H:%M:%S\",time.localtime())\n",
    "            # Write result.\n",
    "            write_results(result_file, f\"{t}-seed{manual_seed}-{score_name}\", macro_f1)\n",
    "        \n",
    "        # Write mean result for all seeds.\n",
    "        seeds_means_f1_score = sum(seed_scores) / len(seed_scores)\n",
    "        write_results(result_file, f\"0-mean-{score_name}\", seeds_means_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monolingual SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/transformers_mono_SR_per_language.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_name in ['C', 'C++', 'C#', 'Java', 'JS/TS', 'Python', 'SQL']:\n",
    "    train_data = SR_data[SR_data.ProgrammingLanguageID != lang_name]\n",
    "    test_data = SR_data[SR_data.ProgrammingLanguageID == lang_name]\n",
    "    print(f\"{lang_name} train_shape={train_data.shape} test_shape={test_data.shape} total_comments={train_data.shape[0]+test_data.shape[0]}\")\n",
    "\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"classla/bcms-bertic\", num_epochs=1)\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"classla/bcms-bertic\", num_epochs=3)\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"classla/bcms-bertic\", num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monolingual EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/transformers_mono_EN_per_language.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_name in ['C', 'C++', 'C#', 'Java', 'JS/TS', 'PHP', 'Python', 'SQL']:\n",
    "    train_data = EN_data[EN_data.ProgrammingLanguageID != lang_name]\n",
    "    test_data = EN_data[EN_data.ProgrammingLanguageID == lang_name]\n",
    "    print(f\"{lang_name} train_shape={train_data.shape} test_shape={test_data.shape} total_comments={train_data.shape[0]+test_data.shape[0]}\")\n",
    "\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"google/electra-base-discriminator\", num_epochs=1)\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"google/electra-base-discriminator\", num_epochs=3)\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"google/electra-base-discriminator\", num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/transformers_multi_SR_per_language.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in [5, 3, 1]:\n",
    "    for lang_name in ['C', 'C++', 'C#', 'Java', 'JS/TS', 'Python', 'SQL']:\n",
    "        train_data = pd.concat([EN_data, SR_data[SR_data.ProgrammingLanguageID != lang_name]])\n",
    "        test_data = SR_data[SR_data.ProgrammingLanguageID == lang_name]\n",
    "        print(f\"{lang_name} train_shape={train_data.shape} test_shape={test_data.shape} total_comments={train_data.shape[0]+test_data.shape[0]}\")\n",
    "\n",
    "        evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=epoch)\n",
    "        evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", num_epochs=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual EN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/transformers_multi_EN_per_language.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in [5, 3, 1]:\n",
    "    for lang_name in ['C', 'C++', 'C#', 'Java', 'JS/TS', 'PHP', 'Python', 'SQL']:\n",
    "        train_data = pd.concat([SR_data, EN_data[EN_data.ProgrammingLanguageID != lang_name]])\n",
    "        test_data = EN_data[EN_data.ProgrammingLanguageID == lang_name]\n",
    "        print(f\"{lang_name} train_shape={train_data.shape} test_shape={test_data.shape} total_comments={train_data.shape[0]+test_data.shape[0]}\")\n",
    "\n",
    "        evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=epoch)\n",
    "        evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", num_epochs=epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosslingual SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/transformers_cross_SR_per_language.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cross_lang(data_train, data_test, test_lang_names, result_file, model_type, model_name, num_epochs, y_column_names=[\"y8\",\"y6\", \"y2\"], seeds=[11, 17, 23, 47, 62]):\n",
    "    parameter_dict = {}\n",
    "    parameter_dict[\"fp16\"] = False\n",
    "    parameter_dict[\"overwrite_output_dir\"] = True\n",
    "    parameter_dict[\"reprocess_input_data\"] = True\n",
    "    parameter_dict[\"no_cache\"] = True\n",
    "    parameter_dict[\"save_eval_checkpoints\"] = False\n",
    "    parameter_dict[\"save_model_every_epoch\"] = False\n",
    "    parameter_dict[\"use_cached_eval_features\"] = False\n",
    "    parameter_dict[\"output_dir\"] = f\"./Transformers/{model_name}/outputs/\"\n",
    "    parameter_dict[\"cache_dir\"] = f\"./Transformers/{model_name}/cache/\"\n",
    "    parameter_dict[\"tensorboard_dir\"] = f\"./Transformers/{model_name}/runs/\"\n",
    "    parameter_dict[\"silent\"] = True\n",
    "    parameter_dict[\"num_train_epochs\"] = num_epochs\n",
    "    parameter_dict[\"max_seq_length\"] = 512\n",
    "\n",
    "    X_train = data_train[\"Comment\"].astype(str)\n",
    "\n",
    "    for test_lang_name in test_lang_names:\n",
    "        X_test = data_test[data_test.ProgrammingLanguageID == test_lang_name][\"Comment\"].astype(str)\n",
    "        for y_column_name in y_column_names:\n",
    "            seed_scores = []\n",
    "            \n",
    "            for manual_seed in seeds:\n",
    "                parameter_dict[\"manual_seed\"] = manual_seed\n",
    "\n",
    "                y_train = data_train[y_column_name]\n",
    "                y_test = data_test[data_test.ProgrammingLanguageID == test_lang_name][y_column_name]\n",
    "\n",
    "                num_classes = y_test.nunique()\n",
    "\n",
    "                score_name = make_score_name(test_lang_name, f\"epochs{num_epochs}\", model_name, num_classes)\n",
    "                t = time.strftime(\"%H:%M:%S\",time.localtime())\n",
    "                print(f\"-------------------{t} RUNNING {score_name}-seed{manual_seed} with {num_classes} classes.-------------------\")\n",
    "\n",
    "                print(\"X_train shape\", X_train.shape, \"y_train shape\", y_train.shape)\n",
    "\n",
    "                train_df = pd.DataFrame(list(zip(X_train, y_train)), columns=['text', 'labels'])\n",
    "                eval_df = pd.DataFrame(list(zip(X_test, y_test)), columns=['text', 'labels'])\n",
    "\n",
    "                # Create model.\n",
    "                model = ClassificationModel(model_type, model_name, num_labels=y_train.nunique(), use_cuda=True, args=parameter_dict)  # You can set class weights by using the optional weight argument\n",
    "                # Train model.\n",
    "                global_step, training_details = model.train_model(train_df, show_running_loss=False, verbose=False)\n",
    "                print(global_step, training_details)\n",
    "                # Evaluate model.\n",
    "                t = time.strftime(\"%H:%M:%S\",time.localtime())\n",
    "                print(f\"-------------------{t} EVALUATE model-------------------\")\n",
    "                result, y_pred, wrong_predictions = model.eval_model(eval_df, f1=f1_macro_score, verbose=False)\n",
    "\n",
    "                # Get results.\n",
    "                print(\"RESULT \", result)\n",
    "                macro_f1 = result[\"f1\"]\n",
    "                seed_scores.append(macro_f1)\n",
    "\n",
    "                t = time.strftime(\"%H:%M:%S\",time.localtime())\n",
    "                # Write result.\n",
    "                write_results(result_file, f\"{t}-seed{manual_seed}-{score_name}\", macro_f1)\n",
    "            \n",
    "            # Write mean result for all seeds.\n",
    "            seeds_means_f1_score = sum(seed_scores) / len(seed_scores)\n",
    "            write_results(result_file, f\"0-mean-{score_name}\", seeds_means_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in [5, 3, 1]:\n",
    "    evaluate_cross_lang(EN_data, SR_data, ['C', 'C++', 'C#', 'Java', 'JS/TS', 'Python', 'SQL'],\n",
    "                        result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=epoch)\n",
    "    evaluate_cross_lang(EN_data, SR_data, ['C', 'C++', 'C#', 'Java', 'JS/TS', 'Python', 'SQL'],\n",
    "                        result_file, model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", num_epochs=epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crosslingual EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/transformers_cross_EN_per_language.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in [5, 3, 1]:\n",
    "    evaluate_cross_lang(SR_data, EN_data, ['C', 'C++', 'C#', 'Java', 'JS/TS', 'PHP', 'Python', 'SQL'],\n",
    "                        result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=epoch)\n",
    "    evaluate_cross_lang(SR_data, EN_data, ['C', 'C++', 'C#', 'Java', 'JS/TS', 'PHP', 'Python', 'SQL'],\n",
    "                        result_file, model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", num_epochs=epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0571e55f8ecb5572eaff1245df35f6abd89dfb1033fe8a1cd84758258f152333"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
