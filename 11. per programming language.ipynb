{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./data/corpus.csv\"\n",
    "corpus = pd.read_csv(\"./data/corpus.csv\", dtype=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalLanguageID</th>\n",
       "      <th>ProgrammingLanguageID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>ClassM</th>\n",
       "      <th>ClassA</th>\n",
       "      <th>y8</th>\n",
       "      <th>y6</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>#include \"map_in_map.h\"</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>- offsetof(struct bpf_array, value);</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>array-&gt;index_mask = index_mask;</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>bpf_map_charge_move(&amp;array-&gt;map.memory, &amp;mem);</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>C</td>\n",
       "      <td>array-&gt;elem_size = elem_size;</td>\n",
       "      <td>code</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>code</td>\n",
       "      <td>code</td>\n",
       "      <td>non-functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NaturalLanguageID ProgrammingLanguageID  \\\n",
       "0                EN                     C   \n",
       "1                EN                     C   \n",
       "2                EN                     C   \n",
       "3                EN                     C   \n",
       "4                EN                     C   \n",
       "\n",
       "                                          Comment ClassM ClassA    y8    y6  \\\n",
       "0                         #include \"map_in_map.h\"   code   code  code  code   \n",
       "1            - offsetof(struct bpf_array, value);   code   <NA>  code  code   \n",
       "2                 array->index_mask = index_mask;   code   <NA>  code  code   \n",
       "3  bpf_map_charge_move(&array->map.memory, &mem);   code   <NA>  code  code   \n",
       "4                   array->elem_size = elem_size;   code   <NA>  code  code   \n",
       "\n",
       "               y2  \n",
       "0  non-functional  \n",
       "1  non-functional  \n",
       "2  non-functional  \n",
       "3  non-functional  \n",
       "4  non-functional  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR_data = corpus[corpus.NaturalLanguageID == \"SR\"]\n",
    "# Remove IDE to be consistent with other models.\n",
    "SR_data = SR_data[SR_data.y8 != \"ide\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_data = corpus[corpus.NaturalLanguageID == \"EN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_name(lang_name, score_name, model_name, num_classes):\n",
    "    return f\"{lang_name}-{score_name}-{model_name}-{num_classes}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro_score(y, y_pred):\n",
    "    return f1_score(y, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_file, score_name, score_value):\n",
    "    pd.DataFrame(\n",
    "        {\"score_name\": [score_name],\n",
    "        \"score_value\": [score_value]}\n",
    "    ).to_csv(result_file, mode=\"a\", decimal=\",\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lang(data_train, data_test, test_lang_name, result_file, model_type, model_name, num_epochs, y_column_names=[\"y8\",\"y6\", \"y2\"], seeds=[11, 17, 23, 47, 62]):\n",
    "    parameter_dict = {}\n",
    "    parameter_dict[\"fp16\"] = False\n",
    "    parameter_dict[\"overwrite_output_dir\"] = True\n",
    "    parameter_dict[\"reprocess_input_data\"] = True\n",
    "    parameter_dict[\"no_cache\"] = True\n",
    "    parameter_dict[\"save_eval_checkpoints\"] = False\n",
    "    parameter_dict[\"save_model_every_epoch\"] = False\n",
    "    parameter_dict[\"use_cached_eval_features\"] = False\n",
    "    parameter_dict[\"output_dir\"] = f\"./Transformers/{model_name}/outputs/\"\n",
    "    parameter_dict[\"cache_dir\"] = f\"./Transformers/{model_name}/cache/\"\n",
    "    parameter_dict[\"tensorboard_dir\"] = f\"./Transformers/{model_name}/runs/\"\n",
    "    parameter_dict[\"silent\"] = True\n",
    "    parameter_dict[\"num_train_epochs\"] = num_epochs\n",
    "    parameter_dict[\"max_seq_length\"] = 512\n",
    "\n",
    "    X_train = data_train[\"Comment\"].astype(str)\n",
    "    X_test = data_test[\"Comment\"].astype(str)\n",
    "\n",
    "    for y_column_name in y_column_names:\n",
    "        seed_scores = []\n",
    "        \n",
    "        for manual_seed in seeds:\n",
    "            parameter_dict[\"manual_seed\"] = manual_seed\n",
    "\n",
    "            y_train = data_train[y_column_name]\n",
    "            y_test = data_test[y_column_name]\n",
    "\n",
    "            num_classes = y_test.nunique()\n",
    "\n",
    "            score_name = make_score_name(test_lang_name, f\"epochs{num_epochs}\", model_name, num_classes)\n",
    "            print(f\"-------------------RUNNING {score_name}-seed{manual_seed} with {num_classes} classes.-------------------\")\n",
    "\n",
    "            print(\"X_train shape\", X_train.shape, \"y_train shape\", y_train.shape)\n",
    "\n",
    "            train_df = pd.DataFrame(list(zip(X_train, y_train)), columns=['text', 'labels'])\n",
    "            eval_df = pd.DataFrame(list(zip(X_test, y_test)), columns=['text', 'labels'])\n",
    "\n",
    "            # Create model.\n",
    "            model = ClassificationModel(model_type, model_name, num_labels=y_train.nunique(), use_cuda=False, args=parameter_dict)  # You can set class weights by using the optional weight argument\n",
    "            # Train model.\n",
    "            global_step, training_details = model.train_model(train_df, show_running_loss=False, verbose=False)\n",
    "            print(global_step, training_details)\n",
    "            # Evaluate model.\n",
    "            print(f\"-------------------EVALUATE model-------------------\")\n",
    "            result, y_pred, wrong_predictions = model.eval_model(eval_df, f1=f1_macro_score, verbose=False)\n",
    "\n",
    "            # Get results.\n",
    "            print(\"RESULT \", result)\n",
    "            macro_f1 = result[\"f1\"]\n",
    "            seed_scores.append(macro_f1)\n",
    "\n",
    "            # Write result.\n",
    "            write_results(result_file, f\"0-seed{manual_seed}-{score_name}\", macro_f1)\n",
    "        \n",
    "        # Write mean result for all seeds.\n",
    "        seeds_means_f1_score = sum(seed_scores) / len(seed_scores)\n",
    "        write_results(result_file, f\"0-mean-{score_name}\", seeds_means_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monolingual SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"./results/transformers_SR_per_language.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C (4320, 8) (714, 8) 5034\n",
      "-------------------RUNNING C-epochs1-classla/bcms-bertic-7-seed11 with 7 classes.-------------------\n",
      "X_train shape (4320,) y_train shape (4320,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 443M/443M [00:08<00:00, 52.1MB/s] \n",
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 83.0/83.0 [00:00<00:00, 30.9kB/s]\n",
      "Downloading: 100%|██████████| 231k/231k [00:00<00:00, 461kB/s]  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11020/2294485670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mevaluate_lang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"electra\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"classla/bcms-bertic\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mevaluate_lang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"electra\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"classla/bcms-bertic\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mevaluate_lang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"electra\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"classla/bcms-bertic\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11020/27363622.py\u001b[0m in \u001b[0;36mevaluate_lang\u001b[1;34m(data_train, data_test, test_lang_name, result_file, model_type, model_name, num_epochs, y_column_names, seeds)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameter_dict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# You can set class weights by using the optional weight argument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;31m# Train model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_details\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_running_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m# Evaluate model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m                     \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 )\n\u001b[1;32m--> 619\u001b[1;33m             train_dataset = self.load_and_cache_examples(\n\u001b[0m\u001b[0;32m    620\u001b[0m                 \u001b[0mtrain_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[1;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[0;32m   1825\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1827\u001b[1;33m             dataset = ClassificationDataset(\n\u001b[0m\u001b[0;32m   1828\u001b[0m                 \u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mClassificationDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         self.examples, self.labels = build_classification_dataset(\n\u001b[0m\u001b[0;32m    283\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_utils.py\u001b[0m in \u001b[0;36mbuild_classification_dataset\u001b[1;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"classification\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"regression\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "for lang_name in ['C', 'C++', 'C#', 'Java', 'TypeScript', 'Python', 'SQL']:\n",
    "    train_data = SR_data[SR_data.ProgrammingLanguageID != lang_name]\n",
    "    test_data = SR_data[SR_data.ProgrammingLanguageID == lang_name]\n",
    "    print(lang_name, train_data.shape, test_data.shape, train_data.shape[0]+test_data.shape[0])\n",
    "\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"classla/bcms-bertic\", num_epochs=1)\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"classla/bcms-bertic\", num_epochs=3)\n",
    "    evaluate_lang(train_data, test_data, lang_name, result_file, model_type=\"electra\", model_name=\"classla/bcms-bertic\", num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lang_name in ['C', 'C++', 'C#', 'Java', 'JavaScript', 'TypeScript', 'PHP', 'Python', 'SQL']:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
