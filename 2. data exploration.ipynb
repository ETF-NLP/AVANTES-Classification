{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"./data/corpus.csv\", dtype=\"string\")\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming language distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_programming_language_info(corpus, language):\n",
    "    _, axes = plt.subplots(1, 2, sharey=False, sharex=False, figsize=(24, 7))\n",
    "\n",
    "    df = corpus[corpus.NaturalLanguageID == language]\n",
    "    print(f\"Dataframe {language} has shape {df.shape}\") \n",
    "        \n",
    "    # Programming language \n",
    "    print(f\"It contains comments for {df.ProgrammingLanguageID.value_counts().size} programming languages.\")\n",
    "    ax = df[\"ProgrammingLanguageID\"].value_counts().plot(ax = axes[0], kind=\"bar\", title=f\"{language} # of comments per programming language\")\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\"{0:g}\".format(p.get_height()), (p.get_x() + 0.12, p.get_height() + 5))\n",
    "\n",
    "    df[\"ProgrammingLanguageID\"].value_counts(normalize=True).plot.pie(ax = axes[1], autopct=lambda x: \"{:.2f}%\".format(x))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_programming_language_info(corpus, \"SR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_programming_language_info(corpus, \"EN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comment_length(corpus, language):\n",
    "    _, ax = plt.subplots(figsize=(36, 7))\n",
    "\n",
    "    df = corpus[corpus.NaturalLanguageID == language]\n",
    "    print(f\"{language} Average comment length is {df['Comment'].str.len().mean():.2f} characters.\")\n",
    "    print(f\"{language} Maximal comment length is {df['Comment'].str.len().max():.0f} characters.\")\n",
    "\n",
    "    # Comment size distribution\n",
    "    ax = df[\"Comment\"].str.len().plot(kind=\"hist\", ax=ax, bins=100, title=f\"{language} Distribution of comment length\")\n",
    "    for p in [p for p in ax.patches if p.get_height() > 0]:\n",
    "        ax.annotate(str(int(p.get_height())), (p.get_x() * 1.003, p.get_height() * 1.01))\n",
    "    plt.xticks([_ for _ in range(0, 4000, 100)])\n",
    "    # print(df[df[\"Comment\"].str.len() > 1000][\"Comment\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_comment_length(corpus, \"SR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_comment_length(corpus, \"EN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comment_num_words(corpus, language):\n",
    "    _, ax = plt.subplots(figsize=(36, 7))\n",
    "\n",
    "    df = corpus[corpus.NaturalLanguageID == language]\n",
    "    print(f\"{language} Average comment number of words is {df['Comment'].str.split().apply(len).mean():.0f} words.\")\n",
    "    print(f\"{language} Maximal comment number of words is {df['Comment'].str.split().apply(len).max():.0f} words.\")\n",
    "\n",
    "    # Comment size distribution\n",
    "    ax = df['Comment'].str.split().apply(len).plot(kind=\"hist\", ax=ax, bins=100, title=f\"{language} Distribution of comment length\")\n",
    "    for p in [p for p in ax.patches if p.get_height() > 0]:\n",
    "        ax.annotate(str(int(p.get_height())), (p.get_x() * 1.003, p.get_height() * 1.01))\n",
    "    plt.xticks([_ for _ in range(0, 500, 10)])\n",
    "    # print(df[df[\"Comment\"].str.len() > 1000][\"Comment\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_comment_num_words(corpus, \"SR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_comment_num_words(corpus, \"EN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_annotation_data(corpus, language):\n",
    "    _, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "        \n",
    "    df = corpus[corpus.NaturalLanguageID == language]\n",
    "\n",
    "    ax1 = df[\"ClassM\"].value_counts().plot(kind=\"bar\", ax=ax1, title=f\"{language} # of comments per class\")\n",
    "    ax1 = df[\"ClassA\"].value_counts().plot(kind=\"bar\", ax=ax1, color=\"red\")\n",
    "    for p in ax1.patches:\n",
    "        # ax1.annotate(str(p.get_height()), (p.get_x() * 1.003, p.get_height() * 1.01))\n",
    "        ax1.annotate(\"{0:g}\".format(p.get_height()), (p.get_x() + 0.06, p.get_height() + 8))\n",
    "    ax1.legend()\n",
    "\n",
    "\n",
    "    ax2 = df[\"ClassM\"].value_counts().plot(kind=\"pie\", ax=ax2, title=f\"{language} # of comments per class M\", autopct=lambda x: \"{:.2f}%\".format(x))\n",
    "    ax3 = df[\"ClassA\"].value_counts().plot(kind=\"pie\", ax=ax3, title=f\"{language} # of comments per class A\", autopct=lambda x: \"{:.2f}%\".format(x))\n",
    "    \n",
    "    percentages = pd.DataFrame()\n",
    "    percentages[\"ClassM\"] = df[\"ClassM\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    percentages[\"ClassA\"] = df[\"ClassA\"].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    print(f\"{language} \\n\", percentages)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_annotation_data(corpus, \"SR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_annotation_data(corpus, \"EN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_annotation_agreement(corpus, language):\n",
    "    print(f\"Confusion matrix for {language}\")\n",
    "    df = corpus[corpus.NaturalLanguageID == language]\n",
    "    df = df[~df[\"ClassA\"].isna()]\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(7,7))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true=df[\"ClassM\"], y_pred=df[\"ClassA\"], xticks_rotation=\"vertical\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_annotation_agreement(corpus, \"SR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_annotation_agreement(corpus, \"EN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krippendorf alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kri(data):\n",
    "    krp = data[[\"ClassA\", \"ClassM\"]]\n",
    "    krp_data = np.array(krp.T, dtype=str)\n",
    "    return krippendorff.alpha(reliability_data=krp_data, level_of_measurement=\"nominal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krp = corpus[~pd.isna(corpus.ClassA)]\n",
    "\n",
    "print(\"all\", kri(krp))\n",
    "print(\"en\", kri(krp[krp.NaturalLanguageID == \"EN\"]))\n",
    "print(\"sr\", kri(krp[krp.NaturalLanguageID == \"SR\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krp.loc[:,\"ClassM\"] = krp[\"ClassM\"].apply(lambda category: \"functional\" if category.startswith(\"functional\") else category)\n",
    "krp.loc[:,\"ClassA\"] = krp[\"ClassA\"].apply(lambda category: \"functional\" if category.startswith(\"functional\") else category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all\", kri(krp))\n",
    "print(\"en\", kri(krp[krp.NaturalLanguageID == \"EN\"]))\n",
    "print(\"sr\", kri(krp[krp.NaturalLanguageID == \"SR\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krp.loc[:,\"ClassM\"] = krp[\"ClassM\"].apply(lambda category: \"functional\" if category.startswith(\"functional\") else \"non-functional\")\n",
    "krp.loc[:,\"ClassA\"] = krp[\"ClassA\"].apply(lambda category: \"functional\" if category.startswith(\"functional\") else \"non-functional\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all\", kri(krp))\n",
    "print(\"en\", kri(krp[krp.NaturalLanguageID == \"EN\"]))\n",
    "print(\"sr\", kri(krp[krp.NaturalLanguageID == \"SR\"]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
