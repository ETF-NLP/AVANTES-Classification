{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649072976261
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_file = \"./data/corpus.csv\"\n",
        "corpus = pd.read_csv(\"./data/corpus.csv\", dtype=\"string\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "corpus[\"y2\"]=pd.Series(le.fit_transform(corpus[\"y2\"]))\n",
        "corpus[\"y6\"]=pd.Series(le.fit_transform(corpus[\"y6\"]))\n",
        "corpus[\"y8\"]=pd.Series(le.fit_transform(corpus[\"y8\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SR data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SR_data = corpus[corpus.NaturalLanguageID == \"SR\"]\n",
        "# Remove IDE to be consistent with other models.\n",
        "SR_data = SR_data[SR_data.y8 != \"ide\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EN data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EN_data = corpus[corpus.NaturalLanguageID == \"EN\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# corpus = corpus.drop(corpus[(corpus.NaturalLanguageID == \"SR\") & (corpus.y8 == \"ide\")].index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_score_name(score_name, model_name, num_classes):\n",
        "    return f\"{score_name}-{model_name}-{num_classes}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1_macro_score(y, y_pred):\n",
        "    return f1_score(y, y_pred, average=\"macro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_results(result_file, score_name, score_value):\n",
        "    pd.DataFrame(\n",
        "        {\"score_name\": [score_name],\n",
        "        \"score_value\": [score_value]}\n",
        "    ).to_csv(result_file, mode=\"a\", decimal=\",\", header=False, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649073008787
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def evaluate(data_base_lang, data_test_lang, result_file, model_type, model_name, num_epochs, y_column_names=[\"y8\",\"y6\", \"y2\"], seeds=[11, 17, 23, 47, 62]):\n",
        "    parameter_dict = {}\n",
        "    parameter_dict[\"fp16\"] = False\n",
        "    parameter_dict[\"overwrite_output_dir\"] = True\n",
        "    parameter_dict[\"reprocess_input_data\"] = True\n",
        "    parameter_dict[\"no_cache\"] = True\n",
        "    parameter_dict[\"save_eval_checkpoints\"] = False\n",
        "    parameter_dict[\"save_model_every_epoch\"] = False\n",
        "    parameter_dict[\"use_cached_eval_features\"] = False\n",
        "    parameter_dict[\"output_dir\"] = f\"./Transformers/{model_name}/outputs/\"\n",
        "    parameter_dict[\"cache_dir\"] = f\"./Transformers/{model_name}/cache/\"\n",
        "    parameter_dict[\"tensorboard_dir\"] = f\"./Transformers/{model_name}/runs/\"\n",
        "    parameter_dict[\"silent\"] = True\n",
        "    parameter_dict[\"num_train_epochs\"] = num_epochs\n",
        "    parameter_dict[\"max_seq_length\"] = 512\n",
        "\n",
        "    X_base_lang = data_base_lang[\"Comment\"].astype(str)\n",
        "    X_test_lang = data_test_lang[\"Comment\"].astype(str)\n",
        "\n",
        "    for y_column_name in y_column_names:\n",
        "        seed_scores = []\n",
        "        \n",
        "        for manual_seed in seeds:\n",
        "            parameter_dict[\"manual_seed\"] = manual_seed\n",
        "\n",
        "            y_base_lang = data_base_lang[y_column_name]\n",
        "            y_test_lang = data_test_lang[y_column_name]\n",
        "\n",
        "            num_classes = y_base_lang.nunique()\n",
        "\n",
        "            score_name = make_score_name(f\"epochs{num_epochs}\", model_name, num_classes)\n",
        "            print(f\"-------------------RUNNING {score_name}-seed{manual_seed} with {num_classes} classes.-------------------\")\n",
        "\n",
        "            cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "            i = 0\n",
        "            f1_scores = []\n",
        "            for train_index, test_index in cv.split(X_test_lang, y_test_lang):\n",
        "                i += 1\n",
        "                print(f\"-------------------RUNNING at index {i}-------------------\")\n",
        "\n",
        "                # Prepare data.\n",
        "                X_train, X_test = X_test_lang.iloc[train_index], X_test_lang.iloc[test_index]\n",
        "                y_train, y_test = y_test_lang.iloc[train_index], y_test_lang.iloc[test_index]\n",
        "            \n",
        "                # print(\"X_train shape\", X_train.shape, \"y_train_Shape\", y_train.shape, X_train.head())\n",
        "\n",
        "                X_train = pd.concat([X_base_lang, X_train], ignore_index=True)\n",
        "                y_train = pd.concat([y_base_lang, y_train], ignore_index=True)\n",
        "\n",
        "                print(\"X_train shape\", X_train.shape, \"y_train shape\", y_train.shape)\n",
        "\n",
        "                train_df = pd.DataFrame(list(zip(X_train, y_train)), columns=['text', 'labels'])\n",
        "                eval_df = pd.DataFrame(list(zip(X_test, y_test)), columns=['text', 'labels'])\n",
        "\n",
        "                # Create model.\n",
        "                model = ClassificationModel(model_type, model_name, num_labels=y_train.nunique(), use_cuda=True, args=parameter_dict)  # You can set class weights by using the optional weight argument\n",
        "                # Train model.\n",
        "                global_step, training_details = model.train_model(train_df, show_running_loss=False, verbose=False)\n",
        "                print(global_step, training_details)\n",
        "                # Evaluate model.\n",
        "                print(f\"-------------------EVALUATE model-------------------\")\n",
        "                result, y_pred, wrong_predictions = model.eval_model(eval_df, f1=f1_macro_score, verbose=False)\n",
        "\n",
        "                # Get results.\n",
        "                print(\"RESULT \", result)\n",
        "                macro_f1 = result[\"f1\"]\n",
        "                f1_scores.append(macro_f1)\n",
        "\n",
        "                # Write result.\n",
        "                write_results(result_file, f\"{i}-seed{manual_seed}-{score_name}\", macro_f1)\n",
        "\n",
        "            # Write mean result for a single seed.\n",
        "            means_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "            seed_scores.append(means_f1_score)\n",
        "            write_results(result_file, f\"0-seed{manual_seed}-{score_name}\", means_f1_score)\n",
        "        \n",
        "        # Write mean result for all seeds.\n",
        "        seeds_means_f1_score = sum(seed_scores) / len(seed_scores)\n",
        "        write_results(result_file, f\"0-mean-{score_name}\", seeds_means_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multilingual bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_file = \"./results/transformers_multi_SR.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=EN_data, data_test_lang=SR_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=EN_data, data_test_lang=SR_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=EN_data, data_test_lang=SR_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=3, y_column_names=[\"y8\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=EN_data, data_test_lang=SR_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=3, y_column_names=[\"y6\", \"y2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=EN_data, data_test_lang=SR_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_file = \"./results/transformers_multi_EN.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=1, y_column_names=[\"y2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [11, 17, 23, 47, 62]\n",
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, \n",
        "        model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", \n",
        "        num_epochs=3, y_column_names=[\"y8\", \"y6\"], seeds=[11, 17, 23])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, \n",
        "        model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", \n",
        "        num_epochs=3, y_column_names=[\"y2\"], seeds=[11, 17, 23, 47, 62])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, model_type=\"bert\", model_name=\"bert-base-multilingual-cased\", num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multilingual roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [11, 17, 23, 47, 62]\n",
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, \n",
        "        model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\",\n",
        "        num_epochs=1, y_column_names=[\"y8\"], seeds=[47, 62])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [11, 17, 23, 47, 62]\n",
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, \n",
        "        model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\",\n",
        "        num_epochs=1, y_column_names=[\"y6\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# [11, 17, 23, 47, 62]\n",
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, \n",
        "        model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\",\n",
        "        num_epochs=1, y_column_names=[\"y2\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", num_epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", num_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(data_base_lang=SR_data, data_test_lang=EN_data, result_file=result_file, model_type=\"xlmroberta\", model_name=\"xlm-roberta-base\", num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9edaf9249fe17bf5a7b2b7c4272fe6657c54e4764c41e6aa9c7b92df235f6c13"
    },
    "kernel_info": {
      "name": "newenvtf"
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
